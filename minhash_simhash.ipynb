{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timing(function):\n",
    "    import time   \n",
    "    \n",
    "    def wrapper(*a):\n",
    "        start = time.time()\n",
    "        function(*a)\n",
    "        stop = time.time()\n",
    "        print('Выполнение {} - {:f} секунд.\\n'.format(function.__name__, stop - start))\n",
    "    return wrapper\n",
    "\n",
    "def make_shingle_set(file, encod='utf8', N_shingle=3):\n",
    "    set_text = set()\n",
    "    with open(file, 'r', encoding=encod) as f:\n",
    "        text = re.sub(r'[^\\w\\ ]', '', f.read()).lower().split(' ')\n",
    "        for item in range(len(text) - N_shingle):\n",
    "            set_text.add(' '.join(text[item:item + N_shingle]))\n",
    "    return set_text\n",
    "    \n",
    "\n",
    "class UniversalHash:\n",
    "    def __init__(self, size=2**32): \n",
    "        self._m = size\n",
    "        self._p = self.generate_prime()\n",
    "        self._a = random.randint(0, self._p)\n",
    "        self._b = random.randint(1, self._p)\n",
    "\n",
    "    def hash(self, key): \n",
    "        if isinstance(key, int):\n",
    "            summ = key\n",
    "        else:\n",
    "            string = str(key)\n",
    "            summ = 0\n",
    "            for item in range(len(string)):\n",
    "                summ = summ + ord(string[item]) * (item + 1)\n",
    "        return (((self._a * summ + self._b) % self._p) % (self._m - 1))\n",
    "\n",
    "    def generate_prime(self):\n",
    "        while True:\n",
    "            p = random.randrange(self._m, self._m << 1)\n",
    "            if all(p % n != 0 for n in range(3, int((p ** 0.5) + 1), 2)):\n",
    "                return p\n",
    "            \n",
    "            \n",
    "def calculate_signature(hash_list):\n",
    "    result = np.zeros(32, dtype='int')\n",
    "    for item in hash_list:\n",
    "        count = []\n",
    "        for i in range(32):\n",
    "            count.append(1) if item & 1 else count.append(-1)\n",
    "            item >>= 1\n",
    "            count.reverse()\n",
    "        result += np.array(count, dtype='int')\n",
    "    result[result < 0] = 0\n",
    "    result[result > 0] = 1\n",
    "    return result\n",
    "\n",
    "\n",
    "def calculate_hamming_distance(sign_1, sign_2):\n",
    "    return sum(np.bitwise_xor(sign_1,sign_2))\n",
    "\n",
    "@timing\n",
    "def minhash(file_1, file_2, encoding='utf8', N_shingle=3, max_error=0.05, hash_size=2**32):  \n",
    "    \n",
    "    set_text_1 = make_shingle_set(file_1, encod=encoding, N_shingle=N_shingle)\n",
    "    set_text_2 = make_shingle_set(file_2, encod=encoding, N_shingle=N_shingle)\n",
    "    \n",
    "    # jaccard\n",
    "    jacc_sim = len(set_text_1.intersection(set_text_2)) / len(set_text_1.union(set_text_2))\n",
    "    print(f\"Jaccard: {jacc_sim}.\")\n",
    "     \n",
    "    # создаем набор hash функций\n",
    "    N_hash = round(1 / (max_error * max_error))\n",
    "    hash_funcs = []\n",
    "    for i in range(N_hash):\n",
    "        h = UniversalHash(hash_size)\n",
    "        hash_funcs.append(h)\n",
    "        \n",
    "    # minhash\n",
    "    hash_set_1 = [min([h.hash(e) for e in set_text_1]) for h in hash_funcs]\n",
    "    hash_set_2 = [min([h.hash(e) for e in set_text_2]) for h in hash_funcs]\n",
    "    \n",
    "    minhash_sim = sum(int(hash_set_1[i] == hash_set_2[i]) for i in range(N_hash)) / N_hash\n",
    "    print(f\"MinHash : {minhash_sim}.\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing\n",
    "def simhash(file_1, file_2, encoding='utf8', N_shingle=3, hash_size=2 ** 32):  \n",
    "    set_text_1 = make_shingle_set(file_1, encod=encoding, N_shingle=N_shingle)\n",
    "    set_text_2 = make_shingle_set(file_2, encod=encoding, N_shingle=N_shingle)\n",
    "    \n",
    "    h = UniversalHash(hash_size)\n",
    "        \n",
    "    hash_list_1 = [h.hash(e) for e in set_text_1]\n",
    "    hash_list_2 = [h.hash(e) for e in set_text_2]\n",
    "    \n",
    "    signature_1 = calculate_signature(hash_list_1)\n",
    "    signature_2 = calculate_signature(hash_list_2)\n",
    "    print(f'Simhash. Hamming distance: {calculate_hamming_distance(signature_1, signature_2)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard: 0.00013489936507365505.\n",
      "MinHash : 0.05.\n",
      "Выполнение minhash - 120.360846 секунд.\n",
      "\n",
      "Simhash. Hamming distance: 13.\n",
      "Выполнение simhash - 3.391059 секунд.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# сравнение первого и второго тома \"Война и мир\"\n",
    "file_1 = 'tom_1.txt'\n",
    "file_2 = 'tom_2.txt'\n",
    "encoding  = 'cp1251'\n",
    "max_error = 0.1\n",
    "N_shingle = 6\n",
    "hash_size = 2 ** 32\n",
    "\n",
    "minhash(file_1, file_2, encoding, N_shingle, max_error, hash_size)\n",
    "simhash(file_1, file_2, encoding, N_shingle, hash_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard: 0.0.\n",
      "MinHash : 0.04.\n",
      "Выполнение minhash - 115.666098 секунд.\n",
      "\n",
      "Simhash. Hamming distance: 14.\n",
      "Выполнение simhash - 3.196705 секунд.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# сравнение произведений разных авторов\n",
    "file_1 = 'tom_1.txt'\n",
    "file_2 = 'tolkien.txt'\n",
    "encoding  = 'cp1251'\n",
    "max_error = 0.1\n",
    "N_shingle = 6\n",
    "hash_size = 2 ** 32\n",
    "\n",
    "minhash(file_1, file_2, encoding, N_shingle, max_error, hash_size)\n",
    "simhash(file_1, file_2, encoding, N_shingle, hash_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tom_1.txt', 'r', encoding='cp1251') as f_r:\n",
    "    with open('tom_1_reduce.txt', 'w', encoding='cp1251') as f_w: \n",
    "        f_w.write(f_r.read()[:-10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard: 0.9864871209773596.\n",
      "MinHash : 0.97.\n",
      "Выполнение minhash - 118.907702 секунд.\n",
      "\n",
      "Simhash. Hamming distance: 0.\n",
      "Выполнение simhash - 3.243857 секунд.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# сравнение полного текста с незначительно урезанной копией\n",
    "file_1 = 'tom_1.txt'\n",
    "file_2 = 'tom_1_reduce.txt'\n",
    "encoding  = 'cp1251'\n",
    "max_error = 0.1\n",
    "N_shingle = 6\n",
    "hash_size = 2 ** 32\n",
    "\n",
    "minhash(file_1, file_2, encoding, N_shingle, max_error, hash_size)\n",
    "simhash(file_1, file_2, encoding, N_shingle, hash_size)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Поиск похожих элементов по simhash  не реализовывался. Длина хеша - 32 бита, (при вычислении  64 битного хеша - алгоритм нахождения простого числа для хеш-функции работает очень долго (но это отдельная задача)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard: 0.00013489936507365505.\n",
      "MinHash : 0.82.\n",
      "Выполнение minhash - 136.508347 секунд.\n",
      "\n",
      "Simhash. Hamming distance: 7.\n",
      "Выполнение simhash - 3.460364 секунд.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_1 = 'tom_1.txt'\n",
    "file_2 = 'tom_2.txt'\n",
    "encoding  = 'cp1251'\n",
    "max_error = 0.1\n",
    "N_shingle = 6\n",
    "hash_size = 2 ** 16\n",
    "\n",
    "minhash(file_1, file_2, encoding, N_shingle, max_error, hash_size)\n",
    "simhash(file_1, file_2, encoding, N_shingle, hash_size)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "При уменьшении разрядности хеша - уменьшается точность, время выполнения остается соразмерным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard: 0.00013489936507365505.\n",
      "MinHash : 0.05.\n",
      "Выполнение minhash - 126.236976 секунд.\n",
      "\n",
      "Simhash. Hamming distance: 10.\n",
      "Выполнение simhash - 3.318329 секунд.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_1 = 'tom_1.txt'\n",
    "file_2 = 'tom_2.txt'\n",
    "encoding  = 'cp1251'\n",
    "max_error = 0.1\n",
    "N_shingle = 6\n",
    "hash_size = 2 ** 24\n",
    "\n",
    "minhash(file_1, file_2, encoding, N_shingle, max_error, hash_size)\n",
    "simhash(file_1, file_2, encoding, N_shingle, hash_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
