{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_shingle_set(file, encod='utf8', N_shingle=3):\n",
    "    set_text = set()\n",
    "    with open(file, 'r', encoding=encod) as f:\n",
    "        text = re.sub(r'[^\\w\\ ]', '', f.read()).lower().split(' ')\n",
    "        for item in range(len(text) - N_shingle):\n",
    "            set_text.add(' '.join(text[item:item + N_shingle]))\n",
    "    return set_text\n",
    "    \n",
    "\n",
    "class UniversalHash:\n",
    "    def __init__(self, size): \n",
    "        self._m = size\n",
    "#         self._p = self.generate_prime(min_border)\n",
    "        self._p = self.generate_prime()\n",
    "        self._a = random.randint(0, self._p)\n",
    "        self._b = random.randint(1, self._p)\n",
    "\n",
    "    def hash(self, key): \n",
    "        if isinstance(key, int):\n",
    "            summ = key\n",
    "        else:\n",
    "            string = str(key)\n",
    "            summ = 0\n",
    "            for item in range(len(string)):\n",
    "                summ = summ + ord(string[item]) * (item + 1)\n",
    "        return (((self._a * summ + self._b) % self._p) % (self._m - 1))\n",
    "\n",
    "    def generate_prime(self):\n",
    "        while True:\n",
    "#             p = random.randrange(min_border, min_border ** 1.5)\n",
    "            p = random.randrange(2 ** 32, 2 ** 34)\n",
    "            if all(p % n != 0 for n in range(3, int((p ** 0.5) + 1), 2)):\n",
    "                return p\n",
    "            \n",
    "            \n",
    "def calculate_signature(set_hash):\n",
    "    result = np.zeros(32, dtype='int')\n",
    "    for item in set_hash:\n",
    "        count = []\n",
    "        for i in range(32):\n",
    "            count.append(1) if item & 1 else count.append(-1)\n",
    "            item >>= 1\n",
    "            count.reverse()\n",
    "        result += np.array(count, dtype='int')\n",
    "    result[result < 0] = 0\n",
    "    result[result > 0] = 1\n",
    "    return result\n",
    "\n",
    "\n",
    "def calculate_hamming_distance(sign_1, sign_2):\n",
    "    return sum(np.bitwise_xor(sign_1,sign_2))\n",
    "\n",
    "\n",
    "def minhash(file_1, file_2, encoding='utf8', N_shingle=3, max_error=0.05):  \n",
    "    \n",
    "    set_text_1 = make_shingle_set(file_1, encod=encoding, N_shingle=N_shingle)\n",
    "    set_text_2 = make_shingle_set(file_2, encod=encoding, N_shingle=N_shingle)\n",
    "    \n",
    "    # jaccard\n",
    "    jacc_sim = len(set_text_1.intersection(set_text_2)) / len(set_text_1.union(set_text_2))\n",
    "    print(f\"Jaccard: {jacc_sim}.\")\n",
    "     \n",
    "    # создаем набор hash функций\n",
    "    N_hash = round(1 / (max_error * max_error))\n",
    "    hash_funcs = []\n",
    "    for i in range(N_hash):\n",
    "        h = UniversalHash(2 ** 32 - 1)\n",
    "        hash_funcs.append(h)\n",
    "        \n",
    "    # minhash\n",
    "    hash_set_1 = [min([h.hash(e) for e in set_text_1]) for h in hash_funcs]\n",
    "    hash_set_2 = [min([h.hash(e) for e in set_text_2]) for h in hash_funcs]\n",
    "    \n",
    "    minhash_sim = sum(int(hash_set_1[i] == hash_set_2[i]) for i in range(N_hash)) / N_hash\n",
    "    print(f\"MinHash : {minhash_sim}.\")\n",
    "    \n",
    "    # simhash    \n",
    "    # Добавлено только для демонстрации, чтоб повторно не выполнять создание шинглов, хеш функций, хеширования шинглов\n",
    "    # отдельная функция simhash - представлена далее.\n",
    "    signature_1 = calculate_signature(hash_set_1)\n",
    "    signature_2 = calculate_signature(hash_set_2)\n",
    "    print(f'SimHash. Hamming distance: {calculate_hamming_distance(signature_1, signature_2)}.')\n",
    "    \n",
    "\n",
    "def simhash(file_1, file_2, encoding='utf8', N_shingle=3, max_error=0.05):  \n",
    "    set_text_1 = make_shingle_set(file_1, encod=encoding, N_shingle=N_shingle)\n",
    "    set_text_2 = make_shingle_set(file_2, encod=encoding, N_shingle=N_shingle)\n",
    "    \n",
    "    N_hash = round(1 / (max_error * max_error))\n",
    "    hash_funcs = []\n",
    "    for i in range(N_hash):\n",
    "        h = UniversalHash(2 ** 32 - 1)\n",
    "        hash_funcs.append(h)\n",
    "        \n",
    "    hash_set_1 = [min([h.hash(e) for e in set_text_1]) for h in hash_funcs]\n",
    "    hash_set_2 = [min([h.hash(e) for e in set_text_2]) for h in hash_funcs]\n",
    "    \n",
    "    signature_1 = calculate_signature(hash_set_1)\n",
    "    signature_2 = calculate_signature(hash_set_2)\n",
    "    print(f'Simhash. Hamming distance: {calculate_hamming_distance(signature_1, signature_2)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaccard: 0.00013489936507365505.\n",
      "min-hash : 0.08.\n",
      "Hamming distance: 5.\n"
     ]
    }
   ],
   "source": [
    "# сравнение первого и второго тома \"Война и мир\"\n",
    "file_1 = 'tom_1.txt'\n",
    "file_2 = 'tom_2.txt'\n",
    "encoding  = 'cp1251'\n",
    "max_error = 0.1\n",
    "N_shingle = 6\n",
    "\n",
    "minhash(file_1, file_2, encoding, N_shingle, max_error)\n",
    "# simhash(file_1, file_2, encoding, N_shingle, max_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaccard: 0.0.\n",
      "min-hash : 0.07.\n",
      "Hamming distance: 5.\n"
     ]
    }
   ],
   "source": [
    "# сравнение произведений разных авторов\n",
    "file_1 = 'tom_1.txt'\n",
    "file_2 = 'tolkien.txt'\n",
    "encoding  = 'cp1251'\n",
    "max_error = 0.1\n",
    "N_shingle = 6\n",
    "\n",
    "minhash(file_1, file_2, encoding, N_shingle, max_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tom_1.txt', 'r', encoding='cp1251') as f_r:\n",
    "    with open('tom_1_reduce.txt', 'w', encoding='cp1251') as f_w: \n",
    "        f_w.write(f_r.read()[:-10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaccard: 0.9864871209773596.\n",
      "min-hash : 0.99.\n",
      "Hamming distance: 0.\n"
     ]
    }
   ],
   "source": [
    "# сравнение полного текста с незначительно урезанной копией\n",
    "file_1 = 'tom_1.txt'\n",
    "file_2 = 'tom_1_reduce.txt'\n",
    "encoding  = 'cp1251'\n",
    "max_error = 0.1\n",
    "N_shingle = 6\n",
    "\n",
    "minhash(file_1, file_2, encoding, N_shingle, max_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
